{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c991e177-edba-4d16-964c-f22ff38db91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None) # Show all columns\n",
    "pd.set_option(\"display.max_rows\", None) # Show all rows\n",
    "\n",
    "# Display row into about 120 text characters before wrapping to a new line\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "# Read the CSV file\n",
    "# the file is inside data/raw/ folder\n",
    "df = pd.read_csv(\"data/raw/diabetes_prediction_dataset.csv\")\n",
    "\n",
    "# Peek at the first 5 rows\n",
    "df.head() \n",
    "\n",
    "# ======================================= STEP 1: DATA UNDERSTANDING =======================================\n",
    "\n",
    "# Display total rows and column\n",
    "print(\"Shape (rows, columns):\", df.shape)\n",
    "\n",
    "# Display all column names\n",
    "print(\"\\nColumns in the dataset:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Check the data types of each column\n",
    "print(\"Data types of columns:\\n\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Categorical columns:\n",
    "# - gender\n",
    "# - smoking_history\n",
    "\n",
    "# Categorical columns (binary values)\n",
    "# meaning the column has only two unique values. \n",
    "# They represent \"no/yes\" categories\n",
    "# - heart_disease\n",
    "# - hypertension  \n",
    "# - diabetes (TARGET)  \n",
    "# Note: They store integers (0, 1), not strings. \n",
    "# But they are still categorical, because there's only two possible values\n",
    "# These two columns are categorical in meaning, but numerical in storage.\n",
    "\n",
    "# Numerical columns (with decimal point):\n",
    "# - age          \n",
    "# - bmi                    \n",
    "# - HbA1c_level            \n",
    "\n",
    "# Numerical columns (integer):                       \n",
    "# - blood_glucose_level      \n",
    "\n",
    "# Check if missing value exist in every columns\n",
    "print(\"Missing values per column:\\n\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Check if duplicates exist or not\n",
    "print(\"Number of duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "# Count how many people have diabetes (1) and not (0)\n",
    "print(\"Diabetes value counts:\\n\")\n",
    "print(df[\"diabetes\"].value_counts())\n",
    "\n",
    "# Display as percentage too\n",
    "print(\"\\nPercentage distribution:\")\n",
    "print((df[\"diabetes\"].value_counts(normalize=True) * 100).round(2))\n",
    "\n",
    "# Count how many have diabetes (1) vs not (0)\n",
    "counts = df[\"diabetes\"].value_counts()\n",
    "\n",
    "# Create the pie chart\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.pie(counts, labels=[\"No Diabetes (0)\", \"Diabetes (1)\"], autopct=\"%.1f%%\", startangle=90, colors=[\"#6AB7FF\", \"#FF9999\"])\n",
    "plt.title(\"Diabetes Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# ======================================= STEP 2: EDA (Exploratory Data Analysis) =======================================\n",
    "\n",
    "# Check unique values in the two categorical columns\n",
    "print(\"Unique values in 'gender':\")\n",
    "print(df[\"gender\"].unique())\n",
    "\n",
    "print(\"\\nUnique values in 'smoking_history':\")\n",
    "print(df[\"smoking_history\"].unique())\n",
    "\n",
    "# Count how many samples belong to each category\n",
    "\n",
    "print(\"Gender value counts:\")\n",
    "print(df[\"gender\"].value_counts())\n",
    "\n",
    "print(\"\\nSmoking history value counts:\")\n",
    "print(df[\"smoking_history\"].value_counts())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Make the figure\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# --- Gender count plot ---\n",
    "plt.subplot(1,2,1)  # first plot (1 row, 2 columns, position 1)\n",
    "df[\"gender\"].value_counts().plot(kind=\"bar\", color=[\"#C93C20\", \"#924E7D\", \"#00821a\"])\n",
    "plt.title(\"Gender Distribution\")\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# --- Smoking history plot ---\n",
    "plt.subplot(1,2,2)  # second plot (position 2)\n",
    "df[\"smoking_history\"].value_counts().plot(kind=\"bar\", color=[\"#8E402A\", \"#317F43\", \"#1F3A3D\", \"#3B83BD\", \"#686C5E\", \"#7FB5B5\"])\n",
    "plt.title(\"Smoking History Distribution\")\n",
    "plt.xlabel(\"Smoking History\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display total of 0s and 1s \n",
    "# for hypertension and heart_disease\n",
    "# Reminder, these two columns (hypertension and heart_disease)\n",
    "# are categorical columns. They store numeric values, but are categorical in meaning.\n",
    "\n",
    "print(\"Hypertension value counts:\")\n",
    "print(df[\"hypertension\"].value_counts().sort_index())\n",
    "print()\n",
    "\n",
    "print(\"Heart disease value counts:\")\n",
    "print(df[\"heart_disease\"].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "binary_cols = [\"hypertension\", \"heart_disease\"]\n",
    "plt.figure(figsize=(10,4))\n",
    "for i, col in enumerate(binary_cols, 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    df[col].value_counts().sort_index().plot(kind=\"bar\", color=[\"#6AB7FF\", \"#FF9999\"], edgecolor=\"black\")\n",
    "    plt.title(f\"{col} value counts\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks([0, 1], [\"0 (No)\", \"1 (Yes)\"])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# See how continuous columns like \n",
    "# age, bmi, HbA1c_level, blood_glucose_level) are spread out.\n",
    "# It helps detect outliers and skewed data\n",
    "numeric_cols = [\"age\", \"bmi\", \"HbA1c_level\", \"blood_glucose_level\"]\n",
    "\n",
    "df[numeric_cols].hist(figsize=(10,6), bins=30, color=\"#90CAF9\", edgecolor=\"black\")\n",
    "plt.suptitle(\"Distribution of Numeric Features\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ======================================= STEP 3: DATA PREPROCESSING =======================================\n",
    "\n",
    "# Remove duplicates\n",
    "\n",
    "# Count total rows in the dataset\n",
    "before = len(df)\n",
    "\n",
    "print(f\"Current rows: {before}\")\n",
    "\n",
    "# Display total duplicates\n",
    "print(\"Number of duplicate rows: \", df.duplicated().sum())\n",
    "\n",
    "# Remove the duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Count total rows in the dataset after removing duplicate rows\n",
    "after = len(df)\n",
    "\n",
    "print(f\"Removed {before - after} duplicate rows.\")\n",
    "print(f\"Remaining rows: {after}\")\n",
    "\n",
    "# Check for invalid values (0 or negative) in key numeric columns\n",
    "\n",
    "invalid_rows = df[\n",
    "    (df['age'] <= 0) |\n",
    "    (df['bmi'] <= 0) |\n",
    "    (df['HbA1c_level'] <= 0) |\n",
    "    (df['blood_glucose_level'] <= 0)\n",
    "]\n",
    "\n",
    "print(\"Number of rows with invalid values:\", len(invalid_rows))\n",
    "invalid_rows.head()\n",
    "\n",
    "# Detect outliers using IQR method for key numeric columns\n",
    "\n",
    "cols_to_check = [\"age\", \"bmi\", \"HbA1c_level\", \"blood_glucose_level\"]\n",
    "\n",
    "for col in cols_to_check:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[col] < lower) | (df[col] > upper)]\n",
    "    \n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  Q1 = {Q1:.2f}, Q3 = {Q3:.2f}, IQR = {IQR:.2f}\")\n",
    "    print(f\"  Lower bound = {lower:.2f}, Upper bound = {upper:.2f}\")\n",
    "    print(f\"  Outlier count = {len(outliers)}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Check unique values and their counts for categorical columns\n",
    "\n",
    "cat_cols = [\"gender\", \"smoking_history\"]\n",
    "\n",
    "for col in cat_cols:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(df[col].value_counts())\n",
    "\n",
    "# Remove rows where gender is 'Other'\n",
    "# because this value is the lowest compared to Male and Female\n",
    "\n",
    "before = len(df)\n",
    "df = df[df[\"gender\"] != \"Other\"]\n",
    "after = len(df)\n",
    "\n",
    "print(f\"Removed {before - after} rows with gender='Other'.\")\n",
    "print(f\"Remaining rows: {after}\")\n",
    "print(\"\\nUpdated gender counts:\")\n",
    "print(df[\"gender\"].value_counts())\n",
    "\n",
    "# Save the preprocessed data as a new csv file\n",
    "processed_dir = Path(\"data/processed\")\n",
    "\n",
    "out_path = processed_dir / \"preprocessed_diabetes_prediction_dataset.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved to:\", out_path.resolve())\n",
    "\n",
    "df_preprocessed = pd.read_csv(\"data/processed/preprocessed_diabetes_prediction_dataset.csv\")\n",
    "\n",
    "print(\"Shape (rows, columns):\", df_preprocessed.shape)\n",
    "df_preprocessed.head()\n",
    "\n",
    "del df\n",
    "\n",
    "# Count how many people have diabetes (1) and not (0)\n",
    "print(\"Diabetes value counts:\\n\")\n",
    "print(df_preprocessed[\"diabetes\"].value_counts())\n",
    "\n",
    "# Display as percentage too\n",
    "print(\"\\nPercentage distribution:\")\n",
    "print((df_preprocessed[\"diabetes\"].value_counts(normalize=True) * 100).round(2))\n",
    "\n",
    "# Count how many have diabetes (1) vs not (0)\n",
    "counts = df_preprocessed[\"diabetes\"].value_counts()\n",
    "\n",
    "# Create the pie chart\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.pie(counts, labels=[\"No Diabetes (0)\", \"Diabetes (1)\"], autopct=\"%.1f%%\", startangle=90, colors=[\"#6AB7FF\", \"#FF9999\"])\n",
    "plt.title(\"Diabetes Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Count how many samples belong to each category\n",
    "\n",
    "print(\"Gender value counts:\")\n",
    "print(df_preprocessed[\"gender\"].value_counts())\n",
    "\n",
    "print(\"\\nSmoking history value counts:\")\n",
    "print(df_preprocessed[\"smoking_history\"].value_counts())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Make the figure\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# --- Gender count plot ---\n",
    "plt.subplot(1,2,1)  # first plot (1 row, 2 columns, position 1)\n",
    "df_preprocessed[\"gender\"].value_counts().plot(kind=\"bar\", color=[\"#C93C20\", \"#924E7D\", \"#00821a\"])\n",
    "plt.title(\"Gender Distribution\")\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# --- Smoking history plot ---\n",
    "plt.subplot(1,2,2)  # second plot (position 2)\n",
    "df_preprocessed[\"smoking_history\"].value_counts().plot(kind=\"bar\", color=[\"#8E402A\", \"#317F43\", \"#1F3A3D\", \"#3B83BD\", \"#686C5E\", \"#7FB5B5\"])\n",
    "plt.title(\"Smoking History Distribution\")\n",
    "plt.xlabel(\"Smoking History\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display total of 0s and 1s \n",
    "# for hypertension and heart_disease\n",
    "# Reminder, these two columns (hypertension and heart_disease)\n",
    "# are categorical columns. They store numeric values, but are categorical in meaning.\n",
    "\n",
    "print(\"Hypertension value counts:\")\n",
    "print(df_preprocessed[\"hypertension\"].value_counts().sort_index())\n",
    "print()\n",
    "\n",
    "print(\"Heart disease value counts:\")\n",
    "print(df_preprocessed[\"heart_disease\"].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "binary_cols = [\"hypertension\", \"heart_disease\"]\n",
    "plt.figure(figsize=(10,4))\n",
    "for i, col in enumerate(binary_cols, 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    df_preprocessed[col].value_counts().sort_index().plot(kind=\"bar\", color=[\"#6AB7FF\", \"#FF9999\"], edgecolor=\"black\")\n",
    "    plt.title(f\"{col} value counts\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks([0, 1], [\"0 (No)\", \"1 (Yes)\"])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# See how continuous columns like \n",
    "# age, bmi, HbA1c_level, blood_glucose_level) are spread out.\n",
    "# It helps detect outliers and skewed data\n",
    "numeric_cols = [\"age\", \"bmi\", \"HbA1c_level\", \"blood_glucose_level\"]\n",
    "\n",
    "df_preprocessed[numeric_cols].hist(figsize=(10,6), bins=30, color=\"#90CAF9\", edgecolor=\"black\")\n",
    "plt.suptitle(\"Distribution of Numeric Features\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ======================================= STEP 4: DATA TRANSFORMATION =======================================\n",
    "\n",
    "# Encode gender column\n",
    "# This column has two possible values only (Male and Female. Other value has been removed)\n",
    "# Therefore, we can use binary encoding (0 or 1)\n",
    "\n",
    "# Encode gender.\n",
    "# Female = 0, Male = 1\n",
    "df_preprocessed[\"gender\"] = df_preprocessed[\"gender\"].map({\"Female\": 0, \"Male\": 1})\n",
    "\n",
    "print(df_preprocessed[\"gender\"].value_counts())\n",
    "\n",
    "df_preprocessed.head()\n",
    "\n",
    "# One-hot encode smoking_history column\n",
    "# Meaning it turns text into several 0/1 columns\n",
    "df_preprocessed = pd.get_dummies(\n",
    "    df_preprocessed,\n",
    "    columns=[\"smoking_history\"],\n",
    "    drop_first=True  # drop one category to avoid redundancy\n",
    ")\n",
    "\n",
    "# Display the new columns created\n",
    "print([c for c in df_preprocessed.columns if c.startswith(\"smoking_history_\")])\n",
    "\n",
    "df_preprocessed.head()\n",
    "\n",
    "# Check correlation between all numeric features and the target (diabetes)\n",
    "# .corr() only works with numbers, so this is done after encoding categorical columns\n",
    "# (like gender and smoking_history) into numeric form\n",
    "# Also, we are doing correlation for all columns in the dataset, because they are all numerical columns now.\n",
    "\n",
    "corr = df_preprocessed.corr(numeric_only=True)[\"diabetes\"].sort_values(ascending=False)\n",
    "print(corr)\n",
    "\n",
    "# Besides using correlation, \n",
    "# use boxplots to see if the numerical columns affect the target variable or not\n",
    "\n",
    "# Boxplots: do these numeric features differ between diabetes=0 and 1?\n",
    "numeric_cols = [\"age\", \"bmi\", \"HbA1c_level\", \"blood_glucose_level\"]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.boxplot(data=df_preprocessed, x=\"diabetes\", y=col, color=\"#90CAF9\") \n",
    "    plt.xlabel(\"Diabetes (0 = No, 1 = Yes)\")\n",
    "    plt.ylabel(col)\n",
    "    plt.title(f\"{col} vs Diabetes\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ======================================= STEP 5: TRAINING & TESTING =======================================\n",
    "\n",
    "# Save the transformed dataset as a new csv file\n",
    "processed_dir = Path(\"data/processed\")\n",
    "\n",
    "out_path = processed_dir / \"transformed_diabetes_prediction_dataset.csv\"\n",
    "df_preprocessed.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved to:\", out_path.resolve())\n",
    "\n",
    "df_transformed = pd.read_csv(\"data/processed/transformed_diabetes_prediction_dataset.csv\")\n",
    "\n",
    "print(\"Shape (rows, columns):\", df_transformed.shape)\n",
    "df_transformed.head()\n",
    "\n",
    "del df_preprocessed\n",
    "\n",
    "# Target variable\n",
    "target = \"diabetes\"\n",
    "\n",
    "# Separate X (independent variables) and y (dependent variable)\n",
    "\n",
    "# Store all columns except the target (features used to predict)\n",
    "X = df_transformed.drop(columns=[target])\n",
    "\n",
    "# Store the target variable only (the thing to predict)\n",
    "y = df_transformed[target]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Split the transformed dataset into train and test\n",
    "\n",
    "# X_train --> Features used to teach the model\n",
    "# y_train --> The real answers (prices) for those same training rows\n",
    "\n",
    "# X_test --> Features the model has not seen\n",
    "# y_test --> The real prices for the test rows\n",
    "\n",
    "# Split into train and test sets\n",
    "# - test_size = 0.2   ---> 20% goes to test. 80% goes to train.\n",
    "# - stratify = y      ---> keeps the same 0/1 ratio in both train and test\n",
    "# - random_state = 42 ---> makes the split repeatable (same result every run)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Display the number of rows and columns in each split\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape :\", X_test.shape)\n",
    "\n",
    "# Check that class balance is similar\n",
    "print(\"Train target distribution (%):\")\n",
    "print((y_train.value_counts(normalize=True) * 100).round(2))\n",
    "\n",
    "print(\"\\nTest target distribution (%):\")\n",
    "print((y_test.value_counts(normalize=True) * 100).round(2))\n",
    "\n",
    "# Next step: Scaling\n",
    "\n",
    "# Note:\n",
    "# scaling just means making numbers smaller or larger so they’re on a similar range —\n",
    "# without changing their meaning.\n",
    "# Suppose we have these two columns (just an example)\n",
    "# age           [20, 30, 40, 50]\n",
    "# blood glucose [90, 150, 200, 250]\n",
    "\n",
    "# if you don’t scale them, the model will see:\n",
    "# Age → 50\n",
    "# Glucose → 250\n",
    "\n",
    "# and might think “glucose is more important because it’s bigger” —\n",
    "# even though the scale difference is just units (years vs mg/dL).\n",
    "\n",
    "# what scaling does is it re-centers and resizes the numbers so they’re comparable.\n",
    "\n",
    "# Numeric columns to scale\n",
    "numeric_cols = [\"age\", \"bmi\", \"HbA1c_level\", \"blood_glucose_level\"]\n",
    "\n",
    "\n",
    "# Build a transformer that:\n",
    "# - scales ONLY the numeric columns\n",
    "# - leaves all other columns (the ones with values 0/1) unchanged (hypertension, heart_disease, gender, smoking dummies)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"  # keep other columns as they are (the ones with 0/1 values)\n",
    ")\n",
    "\n",
    "# Fit on training data ONLY, then transform train and test\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled  = preprocessor.transform(X_test)\n",
    "\n",
    "# Note: Its possible, after scaling, it will affect the number of rows and columns of your trained and test sets.\n",
    "# So, its a good idea to check the shape after scaling them.\n",
    "# See if the shape remain the same before and after scaling.\n",
    "\n",
    "# ----- Model 1: Logistic Regression -----\n",
    "# This is a simple and popular algorithm for binary classification (0 or 1 problems)\n",
    "# It tries to find a mathematical relationship between features and the target.\n",
    "\n",
    "# Create and train the model\n",
    "# 'class_weight=\"balanced\"' helps handle the class imbalance (more 0s than 1s)\n",
    "# 'max_iter=1000' increases the limit for training steps, so it can converge properly\n",
    "lr = LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=42)\n",
    "\n",
    "# Train (fit) the model using the training data\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Notes:\n",
    "# lr = LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=42)\n",
    "\n",
    "# 1) class_weight='balanced'\n",
    "# This tells the model:\n",
    "# “If one class (for example, ‘no diabetes’) has many more samples than the other (‘diabetes’), give extra importance to the smaller class.”\n",
    "# Why?\n",
    "# - Because if 90% are “no diabetes” and only 10% are “diabetes”,\n",
    "#   a lazy model could just predict “no diabetes” every time and still get 90% accuracy\n",
    "#   So class_weight=\"balanced\" makes it treat both sides fairly.\n",
    "\n",
    "# 2) max_iter=1000\n",
    "# the MAX number of learning steps (iterations) the solver is allowed to take.\n",
    "# The model improves step-by-step; each step = 1 iteration.\n",
    "# It will STOP EARLY if it finishes before 1000 (so 1000 is just an upper limit).\n",
    "# If this number is too small, you may get a \"ConvergenceWarning\"\n",
    "# (meaning it ran out of steps before finishing learning).\n",
    "\n",
    "# 3) random_state=42\n",
    "# get the same model behavior every time that line of code is run.\n",
    "\n",
    "# Make predictions on the TEST set (data the model has never seen)\n",
    "\n",
    "# y_pred is the model's final decision for each person → 0 = no diabetes, 1 = diabetes\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "# y_proba is the model's confidence for class 1 (diabetes) → a number between 0 and 1\n",
    "y_proba = lr.predict_proba(X_test_scaled)[:, 1]  # gives probability of class 1 (diabetes)\n",
    "\n",
    "# Check how good the model is (on TEST data)\n",
    "\n",
    "print(\"Logistic Regression — Test metrics\")\n",
    "\n",
    "# Accuracy: out of ALL people, how many did it get right?\n",
    "print(\"Accuracy :\", round(accuracy_score(y_test, y_pred), 4))\n",
    "\n",
    "# Precision: of the people it said \"diabetes\" (1), how many truly had diabetes?\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred), 4))\n",
    "\n",
    "# Recall: of all the people who truly had diabetes (1), how many did we correctly find?\n",
    "print(\"Recall   :\", round(recall_score(y_test, y_pred), 4))\n",
    "\n",
    "# F1-score: a single score that balances precision and recall (higher is better)\n",
    "print(\"F1-score :\", round(f1_score(y_test, y_pred), 4))\n",
    "\n",
    "# ROC-AUC: how well the model separates 0 vs 1 across all possible thresholds (higher is better)\n",
    "print(\"ROC-AUC  :\", round(roc_auc_score(y_test, y_proba), 4))\n",
    "\n",
    "# Confusion matrix for logistic regression\n",
    "cm_lr = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_lr, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix — Logistic Regression\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "\n",
    "# Use the same tick labels + rotation style as MLP\n",
    "plt.xticks([0.5, 1.5], [\"Predicted 0 (No Diabetes)\", \"Predicted 1 (Diabetes)\"], rotation=20)\n",
    "plt.yticks([0.5, 1.5], [\"Actual 0 (No Diabetes)\", \"Actual 1 (Diabetes)\"], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# We have more class 0 than class 1.\n",
    "# Oversampling = make extra copies of class 1 in TRAIN so both classes have similar counts.\n",
    "# (Do NOT touch TEST. TEST must stay real.)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Make a new TRAIN set where 0s and 1s are balanced\n",
    "X_train_bal, y_train_bal = ros.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Show class counts before/after (TRAIN only)\n",
    "print(\"Before oversampling:\", y_train.value_counts().to_dict())\n",
    "print(\"After  oversampling:\", y_train_bal.value_counts().to_dict())\n",
    "\n",
    "# ----- Model 2: Neural Network (MLP) -----\n",
    "\n",
    "# MLPClassifier = a simple neural network.\n",
    "# Think of \"hidden_layer_sizes=(64, 32)\" as:\n",
    "# layer 1 has 64 tiny calculators, layer 2 has 32 tiny calculators.\n",
    "# activation=\"relu\"        → helps the network learn non-linear patterns.\n",
    "# solver=\"adam\"            → the method it uses to learn (a good default).\n",
    "# alpha=1e-4               → a small “penalty” to avoid overfitting.\n",
    "# learning_rate_init=0.001 → how big each learning step is.\n",
    "# early_stopping=True      → stop training early if it stops getting better.\n",
    "# n_iter_no_change=10      → “getting better” must happen within 10 checks, or stop.\n",
    "# max_iter=200             → don’t train more than 200 rounds.\n",
    "# random_state=42          → make results repeatable.\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=1e-4,\n",
    "    learning_rate_init=0.001,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=10,\n",
    "    max_iter=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Teach the neural network using the BALANCED TRAIN data\n",
    "mlp.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Make predictions on TEST (data the model never saw)\n",
    "# y_pred_mlp  = final answer (0 or 1)\n",
    "# y_proba_mlp = confidence it is class 1 (a number between 0 and 1)\n",
    "y_pred_mlp  = mlp.predict(X_test_scaled)\n",
    "y_proba_mlp = mlp.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Neural Network (MLP) — Test metrics\")\n",
    "\n",
    "# Accuracy: out of ALL people, how many did it get right?\n",
    "print(\"Accuracy :\", round(accuracy_score(y_test, y_pred_mlp), 4))\n",
    "\n",
    "# Precision: of the people it said \"diabetes\" (1), how many truly had diabetes?\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred_mlp), 4))\n",
    "\n",
    "# Recall: of all the people who truly had diabetes (1), how many did we correctly find?\n",
    "print(\"Recall   :\", round(recall_score(y_test, y_pred_mlp), 4))\n",
    "\n",
    "# F1-score: a single score that balances precision and recall (higher is better)\n",
    "print(\"F1-score :\", round(f1_score(y_test, y_pred_mlp), 4))\n",
    "\n",
    "# ROC-AUC: how well the model separates 0 vs 1 across all possible thresholds (higher is better)\n",
    "print(\"ROC-AUC  :\", round(roc_auc_score(y_test, y_proba_mlp), 4))\n",
    "\n",
    "# cm_mlp is a 2x2 table:\n",
    "# [[TN, FP],\n",
    "#  [FN, TP]]\n",
    "# TN = predicted 0 and was 0\n",
    "# FP = predicted 1 but was 0\n",
    "# FN = predicted 0 but was 1\n",
    "# TP = predicted 1 and was 1\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_mlp, annot=True, fmt=\"d\", cmap=\"Oranges\", cbar=False)\n",
    "plt.title(\"Confusion Matrix — Neural Network (MLP)\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "\n",
    "# Label axes clearly for binary classification\n",
    "plt.xticks([0.5, 1.5], [\"Predicted 0 (No Diabetes)\", \"Predicted 1 (Diabetes)\"], rotation=20)\n",
    "plt.yticks([0.5, 1.5], [\"Actual 0 (No Diabetes)\", \"Actual 1 (Diabetes)\"], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---- Compare Logistic Regression vs MLP on key metrics (bar chart) ----\n",
    "\n",
    "# Calculate metrics for both models\n",
    "lr_metrics = {\n",
    "    \"Accuracy\":  accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\":    recall_score(y_test, y_pred),\n",
    "    \"F1\":        f1_score(y_test, y_pred),\n",
    "    \"ROC-AUC\":   roc_auc_score(y_test, y_proba),\n",
    "}\n",
    "\n",
    "mlp_metrics = {\n",
    "    \"Accuracy\":  accuracy_score(y_test, y_pred_mlp),\n",
    "    \"Precision\": precision_score(y_test, y_pred_mlp),\n",
    "    \"Recall\":    recall_score(y_test, y_pred_mlp),\n",
    "    \"F1\":        f1_score(y_test, y_pred_mlp),\n",
    "    \"ROC-AUC\":   roc_auc_score(y_test, y_proba_mlp),\n",
    "}\n",
    "\n",
    "# Prepare data for plotting\n",
    "labels   = list(lr_metrics.keys())\n",
    "lr_vals  = [lr_metrics[k]  for k in labels]\n",
    "mlp_vals = [mlp_metrics[k] for k in labels]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "w = 0.37  # bar width\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "b1 = plt.bar(x - w/2, lr_vals,  width=w, label=\"Logistic Regression\")\n",
    "b2 = plt.bar(x + w/2, mlp_vals, width=w, label=\"Neural Net (MLP)\")\n",
    "\n",
    "# Add numbers on top of bars (4 decimal places)\n",
    "for bars in (b1, b2):\n",
    "    for rect in bars:\n",
    "        h = rect.get_height()\n",
    "        plt.text(rect.get_x() + rect.get_width()/2, h, f\"{h:.4f}\",\n",
    "                 ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "plt.xticks(x, labels, rotation=15)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Model Performance Comparison (LR vs MLP)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ======================================= STEP 6: MODEL TUNING =======================================\n",
    "\n",
    "# Tune LOGISTIC REGRESSION\n",
    "\n",
    "# Define the model again\n",
    "lr = LogisticRegression(max_iter=1000, class_weight=\"balanced\", solver=\"liblinear\", random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid to test\n",
    "# Tells the computer which settings (parameters) to test\n",
    "# - 'C' controls how strict the model is:\n",
    "#       small C  → simpler model (less flexible)\n",
    "#       big C    → more flexible model (can overfit)\n",
    "# - 'penalty' controls how the model keeps things simple:\n",
    "#       'l1' → can remove less important features\n",
    "#       'l2' → keeps all features but makes their effect smaller\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']        \n",
    "}\n",
    "\n",
    "# GridSearchCV = test every combination of 'C' and 'penalty'\n",
    "# - cv=5: test each combination 5 times with different train/test splits\n",
    "# - scoring='f1': choose the model that has the best F1 score (balance of precision & recall)\n",
    "# - n_jobs=-1: use all CPU cores (faster)\n",
    "# - verbose=1: show progress while running\n",
    "grid_search_lr = GridSearchCV(\n",
    "    estimator=lr,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                 # 5-fold cross-validation\n",
    "    scoring='f1',         # focus on F1 score since dataset is imbalanced\n",
    "    n_jobs=-1,            # use all CPU cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train and test all the combinations on TRAIN data only\n",
    "grid_search_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Show the best settings and its average score\n",
    "# - best_params_ : the setting (C and penalty) that worked best\n",
    "# - best_score_  : how well it did on average (F1 score)print(\"Best parameters:\", grid_search_lr.best_params_)\n",
    "print(\"Best F1 score (cross-validation):\", round(grid_search_lr.best_score_, 4))\n",
    "\n",
    "# Rebuild Logistic Regression using the BEST settings found by GridSearch\n",
    "lr_tuned = LogisticRegression(\n",
    "    C=grid_search_lr.best_params_['C'],             # use the best C (picked by GridSearch)\n",
    "    penalty=grid_search_lr.best_params_['penalty'], # use the best penalty ('l1' or 'l2')\n",
    "    solver=\"liblinear\",          # works with both 'l1' and 'l2' for binary problems\n",
    "    class_weight=\"balanced\",     # treat minority class fairly\n",
    "    max_iter=1000,              # give it enough steps to finish learning\n",
    "    random_state=42              # make results repeatable\n",
    ")\n",
    "\n",
    "# Train the model on the FULL training set\n",
    "# (After GridSearch, we retrain once using all training data with the best settings.)\n",
    "lr_tuned.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_tuned  = lr_tuned.predict(X_test_scaled)\n",
    "y_proba_tuned = lr_tuned.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Show test scores (higher is better)\n",
    "print(\"Logistic Regression (TUNED) — Test metrics\")\n",
    "\n",
    "# Accuracy: out of ALL people, how many did it get right?\n",
    "print(\"Accuracy :\", round(accuracy_score(y_test, y_pred_tuned), 4))\n",
    "\n",
    "# Precision: of the people it said \"diabetes\" (1), how many truly had diabetes?\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred_tuned), 4))\n",
    "\n",
    "# Recall: of all the people who truly had diabetes (1), how many did we correctly find?\n",
    "print(\"Recall   :\", round(recall_score(y_test, y_pred_tuned), 4))\n",
    "\n",
    "# F1-score: a single score that balances precision and recall (higher is better)\n",
    "print(\"F1-score :\", round(f1_score(y_test, y_pred_tuned), 4))\n",
    "\n",
    "# ROC-AUC: how well the model separates 0 vs 1 across all possible thresholds (higher is better)\n",
    "print(\"ROC-AUC  :\", round(roc_auc_score(y_test, y_proba_tuned), 4))\n",
    "\n",
    "cm_tuned = confusion_matrix(y_test, y_pred_tuned)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_tuned, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix — Logistic Regression (TUNED)\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "\n",
    "# match the same axis labels/rotation we used before\n",
    "plt.xticks([0.5, 1.5], [\"Predicted 0 (No Diabetes)\", \"Predicted 1 (Diabetes)\"], rotation=20)\n",
    "plt.yticks([0.5, 1.5], [\"Actual 0 (No Diabetes)\", \"Actual 1 (Diabetes)\"], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Notes:\n",
    "# The reason the tuned Logistic Regression results look identical to the original model is simply that:\n",
    "# the first Logistic Regression already used the best possible parameters.\n",
    "\n",
    "# Both setups lead to almost the same decision boundary and same metrics, because:\n",
    "# - the data is clean and scaled,\n",
    "# - Logistic Regression is a simple linear model (so small changes in regularization don’t change results much),\n",
    "# - and the dataset has a clear pattern, so the model already converged optimally.\n",
    "# So the “tuned” version didn’t make things worse — it just confirmed your defaults were already good\n",
    "\n",
    "# Now, tune MLP (Neural Network)\n",
    "\n",
    "# Start with a base MLP model\n",
    "# activation=\"relu\"     → good default for non-linear patterns\n",
    "# solver=\"adam\"         → common, fast optimizer\n",
    "# early_stopping=True   → stop training if it stops improving\n",
    "# n_iter_no_change=10   → if no improvement for 10 checks, stop\n",
    "# max_iter=200          → do not train more than 200 rounds\n",
    "# random_state=42       → same results every run\n",
    "mlp = MLPClassifier(\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=10,\n",
    "    max_iter=200,\n",
    "    random_state=42\n",
    ")\n",
    "# Tell GridSearch which settings to try\n",
    "# hidden_layer_sizes : how many neurons per hidden layer\n",
    "#    (64,)     → 1 hidden layer with 64 neurons\n",
    "#    (64, 32)  → 2 hidden layers: 64 then 32\n",
    "#    (128, 64) → 2 hidden layers: 128 then 64\n",
    "#    alpha     : regularization strength (bigger = simpler model)\n",
    "#    learning_rate_init  : how big each learning step is\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(64,), (64, 32), (128, 64)],\n",
    "    'alpha': [1e-4, 1e-3, 1e-2],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "# GridSearchCV = try every combo and pick the best\n",
    "# scoring='f1'  → use F1 score (good for imbalanced data)\n",
    "# cv=3          → 3-fold cross-validation (fair average score)\n",
    "# n_jobs=-1     → use all CPU cores (faster)\n",
    "# verbose=1     → show progress\n",
    "grid_search_mlp = GridSearchCV(\n",
    "    estimator=mlp,\n",
    "    param_grid=param_grid_mlp,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "# Run the search on TRAIN data only\n",
    "grid_search_mlp.fit(X_train_scaled, y_train)\n",
    "# Show the best settings and its average F1 across the folds\n",
    "print(\"Best parameters:\", grid_search_mlp.best_params_)\n",
    "print(\"Best F1 score (cross-validation):\", round(grid_search_mlp.best_score_, 4))\n",
    "\n",
    "# Rebuild the MLP with the BEST settings found\n",
    "best_mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64), # 2 hidden layers: first has 128 neurons, second has 64\n",
    "    alpha=0.0001,                 # small regularization (helps reduce overfitting)\n",
    "    learning_rate_init=0.001,     # size of each learning step\n",
    "    activation=\"relu\",            # common non-linear function (good default)\n",
    "    solver=\"adam\",                # the optimizer that updates the weights\n",
    "    early_stopping=True,          # stop early if validation score stops improving\n",
    "    n_iter_no_change=10,          # if no improvement for 10 checks, stop\n",
    "    max_iter=200,                 # don’t train more than 200 rounds\n",
    "    random_state=42               # same results every run\n",
    ")\n",
    "\n",
    "# Train the model using the TRAIN data\n",
    "best_mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the TEST data (unseen during training)\n",
    "# y_pred_best  = final class (0 or 1)\n",
    "# y_proba_best = probability of class 1 (diabetes) for each persony_pred_best = best_mlp.predict(X_test_scaled)\n",
    "y_pred_best  = best_mlp.predict(X_test_scaled)\n",
    "y_proba_best = best_mlp.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Show how good the model is (higher is better)\n",
    "print(\"Neural Network (TUNED) — Test metrics\")\n",
    "\n",
    "# Accuracy: out of ALL people, how many did it get right?\n",
    "print(\"Accuracy :\", round(accuracy_score(y_test, y_pred_best), 4))\n",
    "\n",
    "# Precision: of the people it said \"diabetes\" (1), how many truly had diabetes?\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred_best), 4))\n",
    "\n",
    "# Recall: of all the people who truly had diabetes (1), how many did we correctly find?\n",
    "print(\"Recall   :\", round(recall_score(y_test, y_pred_best), 4))\n",
    "\n",
    "# F1-score: a single score that balances precision and recall (higher is better)\n",
    "print(\"F1-score :\", round(f1_score(y_test, y_pred_best), 4))\n",
    "\n",
    "# ROC-AUC: how well the model separates 0 vs 1 across all possible thresholds (higher is better)\n",
    "print(\"ROC-AUC  :\", round(roc_auc_score(y_test, y_proba_best), 4))\n",
    "\n",
    "cm_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_best, annot=True, fmt=\"d\", cmap=\"Oranges\", cbar=False)\n",
    "plt.title(\"Confusion Matrix — Neural Network (TUNED)\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "\n",
    "# match the same axis labels/rotation as before\n",
    "plt.xticks([0.5, 1.5], [\"Predicted 0 (No Diabetes)\", \"Predicted 1 (Diabetes)\"], rotation=20)\n",
    "plt.yticks([0.5, 1.5], [\"Actual 0 (No Diabetes)\", \"Actual 1 (Diabetes)\"], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Metric values from your results\n",
    "logreg_scores = {\n",
    "    \"Accuracy\": 0.8851,\n",
    "    \"Precision\": 0.4264,\n",
    "    \"Recall\": 0.8762,\n",
    "    \"F1-score\": 0.5736,\n",
    "    \"ROC-AUC\": 0.9596\n",
    "}\n",
    "\n",
    "mlp_scores = {\n",
    "    \"Accuracy\": 0.9703,\n",
    "    \"Precision\": 0.9569,\n",
    "    \"Recall\": 0.6946,\n",
    "    \"F1-score\": 0.8049,\n",
    "    \"ROC-AUC\": 0.9746\n",
    "}\n",
    "\n",
    "# Extract metric names and values\n",
    "metrics = list(logreg_scores.keys())\n",
    "logreg_vals = list(logreg_scores.values())\n",
    "mlp_vals = list(mlp_scores.values())\n",
    "\n",
    "# Bar positions\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "bars1 = plt.bar(x - width/2, logreg_vals, width, label='Logistic Regression (Tuned)', color='#4A90E2')\n",
    "bars2 = plt.bar(x + width/2, mlp_vals, width, label='Neural Network (Tuned)', color='#F5A623')\n",
    "\n",
    "# Labels and formatting\n",
    "plt.xlabel(\"Evaluation Metrics\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Model Performance Comparison — Logistic Regression vs Neural Network\")\n",
    "plt.xticks(x, metrics)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "# Display bars’ numeric values\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval + 0.02, f\"{yval:.2f}\",\n",
    "                 ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
